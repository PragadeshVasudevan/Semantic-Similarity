{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string \n",
    "from string import digits\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\praga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\praga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re, csv, yaml\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.metrics import edit_distance\n",
    "nltk.download('punkt')\n",
    "import itertools\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imfile = pd.read_csv(\"AIT624-imgdataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfile.dropna(axis=0,how=\"all\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [business=1, ceremony=1, festival=1, group=1,...\n",
       "1     [mountain=6, outdoors=6, travel=6, tree=6, fo...\n",
       "2     [people=4, city=3, politics=3, architecture=2...\n",
       "3     [people=28, politics=18, protest=13, travel=1...\n",
       "4     [automobile=1, business=1, police=1, transpor...\n",
       "Name: Concept, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imfile['Concept'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_dict(s):\n",
    "    return re.sub(r'\\W',' ',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfile['list'] = imfile['Concept'].apply(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      business 1  ceremony 1  festival 1  group 1 ...\n",
       "1      mountain 6  outdoors 6  travel 6  tree 6  fo...\n",
       "2      people 4  city 3  politics 3  architecture 2...\n",
       "3      people 28  politics 18  protest 13  travel 1...\n",
       "4      automobile 1  business 1  police 1  transpor...\n",
       "Name: list, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imfile['list'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_num(s):\n",
    "    s = re.sub(\"\\d+\",\" \", s) \n",
    "    return \" \".join(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfile['list'] = imfile['list'].apply(remove_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    business ceremony festival group indoors peopl...\n",
       "1    mountain outdoors travel tree forest landscape...\n",
       "2    people city politics architecture building con...\n",
       "3    people politics protest travel adult nobody ou...\n",
       "4    automobile business police transportation vehicle\n",
       "Name: list, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "imfile['list'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business',\n",
       " 'ceremony',\n",
       " 'festival',\n",
       " 'group',\n",
       " 'indoors',\n",
       " 'people',\n",
       " 'performance',\n",
       " 'religion',\n",
       " 'restaurant']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(imfile['list'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372    adult cabinet facial expression furniture girl...\n",
       "373    people politics travel coast group outdoors ac...\n",
       "374    road people action street transportation trave...\n",
       "375                                                     \n",
       "376    city travel people architecture street politic...\n",
       "377    people architecture travel building outdoors a...\n",
       "378             adult clothing one people portrait women\n",
       "379    nobody architecture garden house luxury modern...\n",
       "380    beach coast leisure recreation relaxation reso...\n",
       "381    architecture building business city cityscape ...\n",
       "382    travel architecture business nobody building p...\n",
       "383    adult architecture building city competition c...\n",
       "384    adult bar beverage cafe commerce counter desk ...\n",
       "385    carpet chair dining table easy chair fireplace...\n",
       "386    people politics adult men police protest road ...\n",
       "387    people recreation swimming water swimming pool...\n",
       "388    adult people outdoors women portrait politics ...\n",
       "389    dwelling furniture house indoors room display ...\n",
       "390    chair contemporary desk dwelling floor furnitu...\n",
       "391    outdoors nobody tree environment nature people...\n",
       "Name: list, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imfile['list'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=392\n",
    "count=0\n",
    "newlist = []\n",
    "while(count<n):\n",
    "    tokens = word_tokenize(imfile['list'][count])\n",
    "    for a in range(0, len(tokens)-2):\n",
    "        for b in range(a+1, len(tokens)-1):\n",
    "            #print(a)\n",
    "            #print(b)\n",
    "            x = wn.synsets(tokens[a])\n",
    "            y = wn.synsets(tokens[b])\n",
    "            #print(x)\n",
    "            #print(y)\n",
    "            if (len(x) != 0) and (len(y) != 0):            \n",
    "                ai = x[0]\n",
    "                bi = y[0]\n",
    "                xyz = ai.wup_similarity(bi)\n",
    "                if xyz is None:\n",
    "                    xyz = 0\n",
    "                if xyz > 0.5:\n",
    "                    tokens[b] = tokens[a]\n",
    "                    #tokens = list(set(tokens))\n",
    "                    #len(tokens)\n",
    "                #print(ai)\n",
    "                #print(bi)\n",
    "                #print(xyz)\n",
    "    #print(tokens)\n",
    "    newlist.append(tokens)\n",
    "    #print(newlist)\n",
    "    #print(len(tokens))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "port = PorterStemmer()\n",
    "wordnet_lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wordnet_lemmatizer.lemmatize(\"dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    stem = [port.stem(i) for i in s]\n",
    "    lem = [wordnet_lemma.lemmatize(i,pos ='n') for i in stem]\n",
    "    return \",\".join([wordnet_lemma.lemmatize(i,pos ='v') for i in lem])\n",
    "    #return lem   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfile['list'] = imfile['list'].apply(normalize)\n",
    "#imfile['list'] = imfile['list'].apply(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since Stemming and Lemmentization doesn't give proper result So we do LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA using Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concept = imfile['Concept'].str.cat(sep=', ') #merging the columns\n",
    "#concept = concept.replace(\"\\\\\", \"\\\\\\\\\") #converting to raw document\n",
    "#concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1067 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=10000,min_df= 1, stop_words='english',use_idf=True, smooth_idf = True,analyzer='word')\n",
    "X_train_tfidf = vectorizer.fit_transform(imfile['list'])\n",
    "X_train_tfidf[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<392x1067 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12309 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=393, n_iter=5,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components =393)\n",
    "X_lsa = lsa.fit(X_train_tfidf)\n",
    "X_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00133409,  0.01223909,  0.00122176, ...,  0.00826164,\n",
       "         0.00539557,  0.00097392],\n",
       "       [-0.00127506, -0.00126453,  0.00642366, ...,  0.02485697,\n",
       "        -0.00129329,  0.0007609 ],\n",
       "       [ 0.00289255,  0.01014152, -0.00132307, ..., -0.00765521,\n",
       "         0.00468253,  0.00317075],\n",
       "       ..., \n",
       "       [ 0.00486597, -0.02425703,  0.0032891 , ...,  0.04744442,\n",
       "         0.00771466, -0.00170934],\n",
       "       [-0.00121957, -0.04690714, -0.00879716, ...,  0.01761861,\n",
       "        -0.00872048,  0.00337087],\n",
       "       [ 0.01654213, -0.00573071, -0.03438837, ..., -0.00646766,\n",
       "        -0.02040382,  0.00063886]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def syn(word, lch_threshold=2.26):\n",
    "    for net1 in wn.synsets(word):\n",
    "        for net2 in wn.all_synsets():\n",
    "            try:\n",
    "                lch = net1.lch_similarity(net2)\n",
    "            except:\n",
    "                continue\n",
    "            # The value to compare the LCH to was found empirically.\n",
    "            # (The value is very application dependent. Experiment!)\n",
    "            if lch >= 0.5:\n",
    "                yield (net1, net2, lch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sim(word1, word2, lch_threshold=2.15, verbose=False):\n",
    "    \"\"\"Determine if two (already lemmatized) words are similar or not.\n",
    "\n",
    "    Call with verbose=True to print the WordNet senses from each word\n",
    "    that are considered similar.\n",
    "\n",
    "    The documentation for the NLTK WordNet Interface is available here:\n",
    "    http://nltk.googlecode.com/svn/trunk/doc/howto/wordnet.html\n",
    "    \"\"\"\n",
    "    from nltk.corpus import wordnet as wn\n",
    "    results = []\n",
    "    for net1 in wn.synsets(word1):\n",
    "        for net2 in wn.synsets(word2):\n",
    "            try:\n",
    "                lch = net1.lch_similarity(net2)\n",
    "            except:\n",
    "                continue\n",
    "            # The value to compare the LCH to was found empirically.\n",
    "            # (The value is very application dependent. Experiment!)\n",
    "            if lch >= lch_threshold:\n",
    "                results.append((net1, net2))\n",
    "    if not results:\n",
    "        return False\n",
    "    if verbose:\n",
    "        for net1, net2 in results:\n",
    "            print(net1)\n",
    "            print(net1.definition)\n",
    "            print(net2)\n",
    "            print(net2.definition)\n",
    "            print('path similarity:')\n",
    "            print(net1.path_similarity(net2))\n",
    "            print('lch similarity:')\n",
    "            print(net1.lch_similarity(net2))\n",
    "            print('wup similarity:')\n",
    "            print(net1.wup_similarity(net2))\n",
    "            print('-' * 79)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a9b731a55f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'abc' is not defined"
     ]
    }
   ],
   "source": [
    "for a, b in itertools.combinations(abc, 2):\n",
    "    sim(a, b, verbose= False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lange(abc):\n",
    "    for a, b in itertools.combinations(abc, 2):\n",
    "        ai = wn.synsets(a)[0]\n",
    "        bi = wn.synsets(b)[0]\n",
    "        print(ai)\n",
    "        print(bi)\n",
    "        xyz = ai.wup_similarity(bi)\n",
    "        if xyz is None:\n",
    "            xyz = 0\n",
    "        xyz = [float(xyz)]\n",
    "        print(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = pd.read_csv('RedCon.csv',delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept_wup</th>\n",
       "      <th>Concept_lch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[business, ceremony, festival, business, indoo...</td>\n",
       "      <td>[business, ceremony, festival, business, indoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mountain, outdoors, travel, tree, forest, lan...</td>\n",
       "      <td>[mountain, outdoors, travel, tree, forest, lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[people, city, politics, architecture, archite...</td>\n",
       "      <td>[people, city, politics, architecture, archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[people, politics, protest, protest, adult, ad...</td>\n",
       "      <td>[people, politics, protest, travel, adult, adu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[automobile, business, business, automobile, v...</td>\n",
       "      <td>[automobile, business, business, transportatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Concept_wup  \\\n",
       "0  [business, ceremony, festival, business, indoo...   \n",
       "1  [mountain, outdoors, travel, tree, forest, lan...   \n",
       "2  [people, city, politics, architecture, archite...   \n",
       "3  [people, politics, protest, protest, adult, ad...   \n",
       "4  [automobile, business, business, automobile, v...   \n",
       "\n",
       "                                         Concept_lch  \n",
       "0  [business, ceremony, festival, business, indoo...  \n",
       "1  [mountain, outdoors, travel, tree, forest, lan...  \n",
       "2  [people, city, politics, architecture, archite...  \n",
       "3  [people, politics, protest, travel, adult, adu...  \n",
       "4  [automobile, business, business, transportatio...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lenth(line):\n",
    "    abc = word_tokenize(line)\n",
    "    abc =  list(set(abc))\n",
    "    return len(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc['Concept_wup'] = rc['Concept_wup'].apply(convert_dict)\n",
    "rc['Concept_lch'] = rc['Concept_lch'].apply(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc['concept'] = imfile['list'].apply(lenth)\n",
    "rc['wup_len'] = rc['Concept_wup'].apply(lenth)\n",
    "rc['lch_len'] = rc['Concept_lch'].apply(lenth)\n",
    "rc['Concepts'] = imfile['Concept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept_wup</th>\n",
       "      <th>Concept_lch</th>\n",
       "      <th>concept</th>\n",
       "      <th>wup_len</th>\n",
       "      <th>lch_len</th>\n",
       "      <th>Concepts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business  ceremony  festival  business  indoo...</td>\n",
       "      <td>business  ceremony  festival  business  indoo...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>[business=1, ceremony=1, festival=1, group=1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mountain  outdoors  travel  tree  forest  lan...</td>\n",
       "      <td>mountain  outdoors  travel  tree  forest  lan...</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>[mountain=6, outdoors=6, travel=6, tree=6, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people  city  politics  architecture  archite...</td>\n",
       "      <td>people  city  politics  architecture  archite...</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>[people=4, city=3, politics=3, architecture=2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people  politics  protest  protest  adult  ad...</td>\n",
       "      <td>people  politics  protest  travel  adult  adu...</td>\n",
       "      <td>110</td>\n",
       "      <td>26</td>\n",
       "      <td>51</td>\n",
       "      <td>[people=28, politics=18, protest=13, travel=1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>automobile  business  business  automobile  v...</td>\n",
       "      <td>automobile  business  business  transportatio...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[automobile=1, business=1, police=1, transpor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Concept_wup  \\\n",
       "0   business  ceremony  festival  business  indoo...   \n",
       "1   mountain  outdoors  travel  tree  forest  lan...   \n",
       "2   people  city  politics  architecture  archite...   \n",
       "3   people  politics  protest  protest  adult  ad...   \n",
       "4   automobile  business  business  automobile  v...   \n",
       "\n",
       "                                         Concept_lch  concept  wup_len  \\\n",
       "0   business  ceremony  festival  business  indoo...        9        6   \n",
       "1   mountain  outdoors  travel  tree  forest  lan...       22       14   \n",
       "2   people  city  politics  architecture  archite...       37       15   \n",
       "3   people  politics  protest  travel  adult  adu...      110       26   \n",
       "4   automobile  business  business  transportatio...        5        3   \n",
       "\n",
       "   lch_len                                           Concepts  \n",
       "0        7   [business=1, ceremony=1, festival=1, group=1,...  \n",
       "1       18   [mountain=6, outdoors=6, travel=6, tree=6, fo...  \n",
       "2       27   [people=4, city=3, politics=3, architecture=2...  \n",
       "3       51   [people=28, politics=18, protest=13, travel=1...  \n",
       "4        4   [automobile=1, business=1, police=1, transpor...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
